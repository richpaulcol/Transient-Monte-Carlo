import pylab as pp
import numpy as np
import chaospy as cp
import os
from Transient_Calcs import *
import pykalman as pk
#import seaborn as sns

from numpy import linalg as la

def nearestPD(A):
    """Find the nearest positive-definite matrix to input

    A Python/Numpy port of John D'Errico's `nearestSPD` MATLAB code [1], which
    credits [2].

    [1] https://www.mathworks.com/matlabcentral/fileexchange/42885-nearestspd

    [2] N.J. Higham, "Computing a nearest symmetric positive semidefinite
    matrix" (1988): https://doi.org/10.1016/0024-3795(88)90223-6
    """

    B = (A + A.T) / 2
    _, s, V = la.svd(B)

    H = np.dot(V.T, np.dot(np.diag(s), V))

    A2 = (B + H) / 2

    A3 = (A2 + A2.T) / 2

    if isPD(A3):
        return A3

    spacing = np.spacing(la.norm(A))
    # The above is different from [1]. It appears that MATLAB's `chol` Cholesky
    # decomposition will accept matrixes with exactly 0-eigenvalue, whereas
    # Numpy's will not. So where [1] uses `eps(mineig)` (where `eps` is Matlab
    # for `np.spacing`), we use the above definition. CAVEAT: our `spacing`
    # will be much larger than [1]'s `eps(mineig)`, since `mineig` is usually on
    # the order of 1e-16, and `eps(1e-16)` is on the order of 1e-34, whereas
    # `spacing` will, for Gaussian random matrixes of small dimension, be on
    # othe order of 1e-16. In practice, both ways converge, as the unit test
    # below suggests.
    I = np.eye(A.shape[0])
    k = 1
    while not isPD(A3):
        mineig = np.min(np.real(la.eigvals(A3)))
        A3 += I * (-mineig * k**2 + spacing)
        k += 1

    return A3
    
def isPD(B):
    """Returns true when input is positive-definite, via Cholesky"""
    try:
        _ = la.cholesky(B)
        return True
    except la.LinAlgError:
        return False

def rescaleCOV(COV,scale):
	from scipy import interpolate
	mymin,mymax = 0,COV.shape[0]-1
	X = np.linspace(mymin,mymax,COV.shape[0])
	Y = np.linspace(mymin,mymax,COV.shape[0])
	x,y = np.meshgrid(X,Y)
	f = interpolate.interp2d(x,y,COV,kind='linear')
	Xnew = np.linspace(mymin,mymax,(COV.shape[0]-1)*scale)                      
	Ynew = np.linspace(mymin,mymax,(COV.shape[0]-1)*scale)
	return (f(Xnew,Ynew)+f(Xnew,Ynew).T)/2.

def demand_generator(filename,node,maxTime,dt,originalFlow,maxFlow,startTime,endTime):
	"""
	This function will create a simple transient demand control file for a single node
	It accepts as arguments:
	'filename' this is the required filename of the output file.
	'node' this is the node name that you want to specify a control on
	'maxTime' this is the simulation maximum time in seconds
	'dt' the simulation dt
	'originalFlow' the original flow at that node as specified in the SS simulation
	'maxFlow' the flow you require after the flow change
	
	"""
	times = np.arange(0,maxTime,dt)
	demands = np.ones(times.shape)*originalFlow
	demands[int(startTime/dt):int(endTime/dt)] = maxFlow
	np.savetxt(filename,np.hstack((np.array(node),demands)),delimiter = ',')

Directory = 'Projects/Pressure_Surges_Models/'
FileName = '5Pipes.inp'
maxTime = 30
dt =0.01
Wavespeed = 1000.
Transient_Times = np.arange(0,maxTime,dt)

#####
# 	The input distributions
#	Upstream Head =  N(20,0.1)  [m]
#	Downstream Flow = N(0.001,0.0001)   [m3/s]
#	Demand at node3 = Exp(0.0005)
#	Roughness = N(1,0.4)

Upstream = cp.Normal(20,0.1)
Downstream = cp.Normal(0.001,0.0001)
Demand = cp.Exponential(0.0005)
Roughness = cp.J(cp.Normal(1,0.4),cp.Normal(1,0.4),cp.Normal(1,0.4),cp.Normal(1,0.4),cp.Normal(1,0.4))

Distributions = cp.J(Upstream,Downstream,Demand,Roughness)
#samples = Distributions.sample(100000,'S')
#np.save(Directory+'Transient_MC_samples.npy',samples)


#
#####		Monte Carlo Method
#
#

samples = np.load(Directory+'Transient_MC_samples.npy')

#Net = Import_EPANet_Geom(Directory+FileName)
#Net.open_epanet_file()


#Iterations = 1
#Output = np.zeros((Iterations,len(Net.nodes),Transient_Times.size))

#ret,reservoir = epa.ENgetnodeindex(str(Net.nodes[-1].Name))
#ret,demand = epa.ENgetnodeindex(str(Net.nodes[1].Name))
#ret,downstream = epa.ENgetnodeindex(str(Net.nodes[-2].Name))

#for i in range(Iterations):
#	print i
#	ret = epa.ENsetnodevalue(reservoir,epa.EN_ELEVATION,samples[0,i])
#	ret = epa.ENsetnodevalue(downstream,epa.EN_BASEDEMAND,samples[1,i]*1000.)
#	ret = epa.ENsetnodevalue(demand,epa.EN_BASEDEMAND,samples[2,i]*1000.)
#	for j in range(len(Net.pipes)):
#		ret,index = epa.ENgetlinkindex(str(Net.pipes[j].Name))
#		ret,epa.ENsetlinkvalue(index,epa.EN_ROUGHNESS,samples[3+j,i])
#		
#	Net.run_epanet_file()				## This function runs the SS EPAnet model	
#	Net.read_results_from_epanet()			## This function reads the SS EPAnet data into the transinet model
#	demand_generator(Directory+'5_pipes_driving_transient.csv',6,maxTime,dt,samples[1,i]*1000.,samples[1,i]*1000.+0.5,2,30)
#	#Net.Assign_Emmiters_All()
#	Net.Constant_Wavespeed(Wavespeed)
#	Net.MOC_Initialisation(dt)
#	Net.Control_Input(Directory+'5_pipes_driving_transient.csv')
#	Net.MOC_Run(maxTime)
#	
#	count = 0					## The next few lines of code reads the output of the nodal pressures and feeds them into the Output array specified earlier.
#	for node in Net.nodes:
#		Output[i,count,:] = node.TranH
#		count+=1
		
#np.save(Directory + '5_pipes_Monte_Carlo_non_pressure_dependent.npy',Output)

######		Linear Transient
##
##	Calculating the mean inputs

Net = Import_EPANet_Geom(Directory+FileName)
Net.open_epanet_file()

####	Setting up the initial condition
ret,reservoir = epa.ENgetnodeindex(str(Net.nodes[-1].Name))
ret,demand = epa.ENgetnodeindex(str(Net.nodes[1].Name))
Net.nodes[1].demand = 0.0005
ret,downstream = epa.ENgetnodeindex(str(Net.nodes[-2].Name))
Net.nodes[-2].demand = 0.001
ret = epa.ENsetnodevalue(reservoir,epa.EN_ELEVATION,20)
ret = epa.ENsetnodevalue(downstream,epa.EN_BASEDEMAND,0.001*1000.)
ret = epa.ENsetnodevalue(demand,epa.EN_BASEDEMAND,0.0005*1000.)
for j in range(len(Net.pipes)):
	ret,index = epa.ENgetlinkindex(str(Net.pipes[j].Name))
	ret,epa.ENsetlinkvalue(index,epa.EN_ROUGHNESS,1)

#####	Running the initial steady state
Net.run_epanet_file()				## This function runs the SS EPAnet model	
Net.read_results_from_epanet()
Net.Constant_Wavespeed(Wavespeed)
Net.Initialise_Linear_Kalman(dt)
Net.Assign_Emmiters_All()
Net.dx = Wavespeed*dt
####	Initialising the Covariance Matrices
COV = np.load(Directory+'InitialCOV.npy')
Var = np.diag(COV)

Net.P_Matrix = Net.P_Matrix.todense()
Net.Q_Matrix = Net.Q_Matrix.todense()
#for i in range(Net.pipes_State_Index.size):
#	for j in range(Net.pipes_State_Index.size):
#		k = Net.pipes_State_Index.astype('int')[i]
#		l = Net.pipes_State_Index.astype('int')[j]
#		Net.P_Matrix[Net.CPs+i,Net.CPs+j] = COV[k,l]
#		Net.P_Matrix[i,j] = COV[k+len(Net.pipes),l+len(Net.pipes)]
		
		
#Net.P_Matrix[:Net.CPs,:Net.CPs] = (np.ones((50,50))*0.15)
#Net.P_Matrix[Net.CPs:2*Net.CPs,Net.CPs:2*Net.CPs] = (np.ones((50,50))*0.01)
#Net.P_Matrix[Net.CPs:Net.CPs+20,Net.CPs:Net.CPs+20] = (np.ones((20,20))*0.26)
Net.P_Matrix[0,0] = 0.1**2  				#Variance in the upstream Head BC#  (i.e. std^2)
Net.P_Matrix[2*Net.CPs+4,2*Net.CPs+4] = 0.0001**2	#Variance in the downstream flow#
Net.P_Matrix[2*Net.CPs+1,2*Net.CPs+1] = 0.0005**2	#Variance in the node 3 demand

Net.P_Matrix[:Net.CPs,:Net.CPs] = rescaleCOV(COV[5:,5:],10)

Net.P_Matrix = np.load(Directory+'InitP.npy')
#Net.Q_Matrix[0,0] = 0.1**2*Net.dt**2  		#Variance in the upstream Head BC#
#Net.Q_Matrix[2*Net.CPs+4,2*Net.CPs+4] = Net.dt**2*0.0001**2	#Variance in the downstream flow#
#Net.Q_Matrix[2*Net.CPs+1,2*Net.CPs+1] = Net.dt**2*0.0005**2	#Variance in the node 3 demand


sigma_lam = 0.00425


#Net.Q_Matrix[Net.CPs:2*Net.CPs,Net.CPs:2*Net.CPs] = np.diag(8 * Net.dx* Net.X_Vector[Net.CPs:2*Net.CPs]**2 / (9.81*0.1**5 * np.pi**2)) * sigma_lam**2


#Net.Q_Matrix[Net.CPs,Net.CPs] = (4*Net.dx)/(9.81*0.1**5*np.pi)*(-Net.X_Vector[Net.CPs+1]**2 + Net.X_Vector[Net.CPs]**2)*sigma_lam**2
#Net.Q_Matrix[2*Net.CPs-1,2*Net.CPs-1] = (4*Net.dx)/(9.81*0.1**5*np.pi)*(-Net.X_Vector[2*Net.CPs-1]**2 + Net.X_Vector[2*Net.CPs-2]**2)*sigma_lam**2



###### Adding the uncertainty to the head on the pipes due to friction 
#Net.Q_Matrix[1:Net.CPs-1,1:Net.CPs-1] =  (4*Net.dx)/(9.81*0.1**5*np.pi)  *  (-Net.X_Vector[Net.CPs+2:2*Net.CPs]**2 + Net.X_Vector[Net.CPs:2*Net.CPs-2]**2)*sigma_lam**2* Net.dt/2.


###### Adding the uncertainty to the flow on the pipes due to friction 
#Net.Q_Matrix[Net.CPs+1:2*Net.CPs-1,Net.CPs+1:2*Net.CPs-1] = (Net.dx/(0.1**3 * np.pi*Wavespeed))  *  (+Net.X_Vector[Net.CPs+2:2*Net.CPs]**2 + Net.X_Vector[Net.CPs:2*Net.CPs-2]**2)  *sigma_lam**2 * Net.dt/2.

#fsfsdfsfs

#kf = pk.KalmanFilter()

#kf.transition_matrices = Net.A_Matrix.todense()

#kf.transition_covariance = Net.Q_Matrix

#kf.initial_state_mean = Net.X_Vector
#kf.initial_state_covariance = Net.P_Matrix
#Simon = kf.transition_matrices
#Dave = Net.regenerateA()
#StateOutput = np.zeros((Net.X_Vector.size,Transient_Times.size))
#VarianceOutput = np.zeros((Net.X_Vector.size,Net.X_Vector.size,Transient_Times.size))
#for i in range(0,Transient_Times.size):
#	if i == int(2/dt):
#		Net.X_Vector[2*Net.CPs+Net.nodes[-2].number]+=0.0005
#		#Net.P_Matrix[2*Net.CPs+4,2*Net.CPs+4] += 0.00001**2
#		
#	Net.X_Vector,Net.P_Matrix = kf.filter_update(Net.X_Vector,Net.P_Matrix)
#	StateOutput[:,i] = Net.X_Vector
#	VarianceOutput[:,:,i] = Net.P_Matrix 

#	kf.transition_matrices = Net.regenerateA()
##	Net.Q_Matrix[1:Net.CPs-1,1:Net.CPs-1] =  (4*Net.dx)/(9.81*0.1**5*np.pi)  *  (-Net.X_Vector[Net.CPs+2:2*Net.CPs]**2 + Net.X_Vector[Net.CPs:2*Net.CPs-2]**2)*sigma_lam**2* Net.dt/2.
##	Net.Q_Matrix[Net.CPs+1:2*Net.CPs-1,Net.CPs+1:2*Net.CPs-1] = (Net.dx/(0.1**3 * np.pi*Wavespeed))  *  (+Net.X_Vector[Net.CPs+2:2*Net.CPs]**2 + Net.X_Vector[Net.CPs:2*Net.CPs-2]**2)  *sigma_lam**2 * Net.dt/2.

#np.save(Directory+'KalmanStateOutput.npy',StateOutput)
#np.save(Directory+'KalmanVarianceOutput.npy',VarianceOutput)

#import Pressure_Surges_Monte_Plotter
##f,axs = pp.subplots(nrows = 2,ncols = 1)
#axs[0].plot(Transient_Times,StateOutput[Net.nodal_CPs['3'],:])
#axs[1].plot(Transient_Times,VarianceOutput[Net.nodal_CPs['3'],Net.nodal_CPs['3'],:]*2)

#f,axs = pp.subplots(nrows = 4,ncols = 2)
#axs[0,0].imshow(Simon[:50,:50])
#axs[0,1].imshow(kf.transition_matrices[:50,:50])

#axs[1,0].imshow(Simon[50:,50:])
#axs[1,1].imshow(kf.transition_matrices[50:,50:])

#axs[2,0].imshow(Simon[:50,50:])
#axs[2,1].imshow(kf.transition_matrices[:50,50:])

#axs[3,0].imshow(Simon[50:,:50])
#axs[3,1].imshow(kf.transition_matrices[50:,:50])

pp.show()


#####	The Unscented Transform
##
#

#Net = Import_EPANet_Geom(Directory+FileName)
#Net.open_epanet_file()
######	Setting up the initial condition
#ret,reservoir = epa.ENgetnodeindex(str(Net.nodes[-1].Name))
#ret,demand = epa.ENgetnodeindex(str(Net.nodes[1].Name))
#Net.nodes[1].demand = 0.0005
#ret,downstream = epa.ENgetnodeindex(str(Net.nodes[-2].Name))
#Net.nodes[-2].demand = 0.001
#ret = epa.ENsetnodevalue(reservoir,epa.EN_ELEVATION,20)
#ret = epa.ENsetnodevalue(downstream,epa.EN_BASEDEMAND,0.001*1000.)
#ret = epa.ENsetnodevalue(demand,epa.EN_BASEDEMAND,0.0005*1000.)
#for j in range(len(Net.pipes)):
#	ret,index = epa.ENgetlinkindex(str(Net.pipes[j].Name))
#	ret,epa.ENsetlinkvalue(index,epa.EN_ROUGHNESS,1)

#####	Running the initial steady state
#Net.run_epanet_file()				# This function runs the SS EPAnet model	
#Net.read_results_from_epanet()
#Net.Constant_Wavespeed(Wavespeed)
#Net.MOC_Initialisation(dt)

#Net.UnscentedInitialise(dt,7)
#State = Net.MOCtoStateVector(Net.X_Vector)
#State[-7:] = 1
#State[-1] = 0.0005
#State[-2] = 0.001
#Net.dx = Wavespeed*dt


##Trans_Variance = np.zeros(State.shape)
##Trans_Variance[:Net.CPs] = 1e-10**2
##Trans_Variance[Net.CPs:2*Net.CPs] = 1e-10**2
##Trans_Variance[0] = 1e-10**2
##Trans_Variance[-1] =1e-15
##Trans_Variance[-2] = 1e-13
##Trans_Variance[-3] = 1e-12
##Trans_Variance[-4] = 1e-14
##Trans_Variance[-5] = 1e-12
##Trans_Variance[-6] = 1e-14
##Trans_Variance[-7] = 1e-13
##Trans_Covariance = np.diag(Trans_Variance)


##Trans_Covariance = np.identity(State.size)
###Trans_Covariance += np.random.normal(1e-4,1e-5,Trans_Covariance.shape)

##Trans_Covariance = nearestPD(Trans_Covariance)

#AUSKF = pk.UnscentedKalmanFilter(Net.UpdateState,transition_covariance =Trans_Covariance)

#P = np.ones(State.shape)*1e-100

##P[:Net.CPs] = 1e-10**2
##P[Net.CPs:2*Net.CPs] = 0.00001**2
#P[0] = 0.1**2
#P[-1] = 0.0005**2/1.6
#P[-2] = 0.0001**2
#P[-3] = 0.4 **2
#P[-4] = 0.4 **2
#P[-5] = 0.4 **2
#P[-6] = 0.4 **2
#P[-7] = 0.4 **2
#P = np.diag(P)
###P = np.identity(State.size)*1e-15
##P += np.random.normal(1e-20,1e-22,P.shape)

##P = nearestPD(P)
#InitP = np.load(Directory+'Initial_P_based_on_SS.npy')
#P[:100,:100] = InitP
##Iterations = 2000
#sigma_lam = 0.00425
#Q = np.identity(State.size)*1e-100

######## Adding the uncertainty to the head on the pipes due to friction 
#Q[1:Net.CPs-1,1:Net.CPs-1] =  (4*Net.dx)/(9.81*0.1**5*np.pi)  *  np.diag(-State[Net.CPs+2:2*Net.CPs]**2 + State[Net.CPs:2*Net.CPs-2]**2)*sigma_lam**2


######## Adding the uncertainty to the flow on the pipes due to friction 
#Q[Net.CPs+1:2*Net.CPs-1,Net.CPs+1:2*Net.CPs-1] = (Net.dx/(0.1**3 * np.pi*Wavespeed))  *  np.diag(-State[Net.CPs+2:2*Net.CPs]**2 - State[Net.CPs:2*Net.CPs-2]**2)  *sigma_lam**2 

##States = np.zeros((State.size,Iterations))
##Ps = np.zeros((State.size,State.size,Iterations))
##States[:,0] = State

##for i in range(1,Iterations):
####	print i
####	
##	if i == 20:
##		State[-2] = np.random.normal(0.0015,0.0001)
##		State[-1] = np.random.exponential(0.0005)
##		State[-3] = np.random.normal(1,0.4)
##		State[-4] = np.random.normal(1,0.4)
##		State[-5] = np.random.normal(1,0.4)
##		State[-6] = np.random.normal(1,0.4)
##		State[-7] = np.random.normal(1,0.4)
####	
####	State,P = AUSKF.filter_update(State,P)
####	P = nearestPD(P)
##	State = Net.UpdateState(State,noise = 0)
##	States[:,i] = State
##	Ps[:,:,i] = P
###	

###f,axs = pp.subplots(nrows = 2,ncols = 1)
###axs[0].plot(States[19,:])
###axs[1].plot(Ps[19,19,:]*2)
####demand_generator(Directory+'5_pipes_driving_transient.csv',6,maxTime,dt,samples[1,i]*1000.,samples[1,i]*1000.+0.5,2,30)
####Net.Control_Input(Directory+'5_pipes_driving_transient.csv')
####Net.MOC_Run(maxTime)

##pp.show()

#from filterpy.kalman import unscented_transform, MerweScaledSigmaPoints, JulierSigmaPoints, JulierSigmaPoints
#import scipy.stats as stats
##InitP = np.load(Directory+'UKFInitP.npy')
##P[:2*Net.CPs,:2*Net.CPs] = InitP[:2*Net.CPs,:2*Net.CPs]

#ukf_mean = State
#ukf_cov = nearestPD(P)

#Iterations = 3000
#points = MerweScaledSigmaPoints(n=State.size, alpha=1e-3, beta=2., kappa=3-State.size)
#points =  JulierSigmaPoints(n=State.size)
#sigmas = points.sigma_points(ukf_mean,ukf_cov)

#sigmas_f = np.empty((Iterations,sigmas.shape[0],sigmas.shape[1]))
#sigmas_f[0,:,:] = sigmas
#for i in range(sigmas.shape[0]):
#	print i
#	
#	#print s
#	ret,reservoir = epa.ENgetnodeindex(str(Net.nodes[-1].Name))
#	ret,demand = epa.ENgetnodeindex(str(Net.nodes[1].Name))
#	Net.nodes[1].demand = sigmas_f[0,i,-1]
#	ret,downstream = epa.ENgetnodeindex(str(Net.nodes[-2].Name))
#	Net.nodes[-2].demand = sigmas_f[0,i,-2]
#	#demand_generator(Directory+'5_pipes_driving_transient.csv',6,maxTime,dt,sigmas_f[0,i,-2]*1000.,sigmas_f[0,i,-2]*1000.+0.5,2,30)https://www.sheffield.ac.uk/
#	#Net.Control_Input(Directory+'5_pipes_driving_transient.csv')
#	
#	ret = epa.ENsetnodevalue(reservoir,epa.EN_ELEVATION,sigmas_f[0,i,0])
#	ret = epa.ENsetnodevalue(downstream,epa.EN_BASEDEMAND,sigmas_f[0,i,-2]*1000.)
#	ret = epa.ENsetnodevalue(demand,epa.EN_BASEDEMAND,sigmas_f[0,i,-1]*1000.)
#	
#	for j in range(len(Net.pipes)):
#		ret,index = epa.ENgetlinkindex(str(Net.pipes[j].Name))
#		ret,epa.ENsetlinkvalue(index,epa.EN_ROUGHNESS,sigmas_f[0,i,2*Net.CPs+j])
#		
#	Net.run_epanet_file()				# This function runs the SS EPAnet model	
#	Net.read_results_from_epanet()
#	Net.Constant_Wavespeed(Wavespeed)
#	Net.MOC_Initialisation(dt)
#	Net.UnscentedInitialise(dt,7)
#	Net.time = 0
#	for j in range(1,Iterations):
#		if j == 200:
#			sigmas_f[j-1,i,-2]+=0.0005
#		Net.time  += Net.dt
#		sigmas_f[j,i,:] = Net.UpdateState(sigmas_f[j-1,i,:])
#		
##wm,wc = points.weights()
#ukf_mean = np.empty((Iterations,State.size))
#ukf_cov = np.empty((Iterations,State.size,State.size))
#ukf_mean[0,:] = State
#ukf_cov[0,:,:] = P
#for j in range(1,Iterations):	
##	Q = np.identity(State.size)*1e-100

##	####### Adding the uncertainty to the head on the pipes due to friction 
##	Q[1:Net.CPs-1,1:Net.CPs-1] =  (4*Net.dx)/(9.81*0.1**5*np.pi)  *  np.diag(-ukf_mean[j-1,Net.CPs+2:2*Net.CPs]**2 + ukf_mean[j-1,Net.CPs:2*Net.CPs-2]**2)*sigma_lam


##	####### Adding the uncertainty to the flow on the pipes due to friction 
##	Q[Net.CPs+1:2*Net.CPs-1,Net.CPs+1:2*Net.CPs-1] = (Net.dx/(0.1**3 * np.pi*Wavespeed))  *  np.diag(-ukf_mean[j-1,Net.CPs+2:2*Net.CPs]**2 - ukf_mean[j-1,Net.CPs:2*Net.CPs-2]**2)  *sigma_lam
#	
#	ukf_mean[j,:], ukf_cov[j,:,:] = unscented_transform(sigmas_f[j,:,:], points.Wm,points.Wc)
#	#ukf_cov = nearestPD(ukf_cov)

##ukf_mean = State
##ukf_cov = nearestPD(P)
##points = MerweScaledSigmaPoints(n=State.size, alpha=1e-2, beta=2., kappa=0)
###points = JulierSigmaPoints(n=State.size,kappa=3-State.size)
##points =  JulierSigmaPoints(n=State.size)
##for i in range(10):
##	sigmas = points.sigma_points(ukf_mean,ukf_cov)
##	sigmas_f = np.empty(sigmas.shape)
##	for i in range(sigmas.shape[0]):
##		sigmas_f[i] = Net.UpdateState(sigmas[i])
##	ukf_mean, ukf_cov = unscented_transform(sigmas_f, points.Wm,points.Wc)	
##	ukf_cov = nearestPD(ukf_cov)

####	PCE
##
#

#samples = np.load(Directory+'Transient_MC_samples.npy')

Output = np.load(Directory +'5_pipes_Monte_Carlo_non_pressure_dependent_Keep.npy',mmap_mode='r')
#Mean = np.load(Directory + '5_pipes_Monte_Carlo_non_pressure_dependent_Mean.npy')
#Std = np.load(Directory + '5_pipes_Monte_Carlo_non_pressure_dependent_Std.npy')


#Node = 0
#Order = 3
#NoSamples = 200
#polynomial_expansion = cp.orth_ttr(Order, Distributions)
#foo_approx = cp.fit_regression(polynomial_expansion, samples[:,:NoSamples], Output[:NoSamples,Node,:])
#expected = cp.E(foo_approx, Distributions)
#deviation = cp.Std(foo_approx, Distributions)
#coefs_kernal = cp.descriptives.misc.QoI_Dist(foo_approx[-1],Distributions)

#f,axs = pp.subplots(figsize=(9, 6),nrows = 2,ncols = 1,sharex=True)
#axs[0].plot(Transient_Times,expected,'k')
#axs[1].plot(Transient_Times,deviation**2,'k')

#axs[0].plot(Transient_Times,Mean[Node,:],'b')
#axs[1].plot(Transient_Times,Std[Node,:]**2,'b')



#axs[1].set_xlabel('Time (s)')
#axs[1].set_ylabel('Variance Head (m)')
#axs[0].set_ylabel('Head (m)')
#axs[0].set_title('Node:' + str(Node+2))

##pp.savefig(Directory+'Monte_PCE_NoSamples'+str(NoSamples)+'_Node'+str(Node+2))

#pp.tight_layout()
#pp.show()
Node = 0
f,axs = pp.subplots(nrows = 1,ncols = 1)
A = axs.hist(Output[:10000,Node,-1],100,density=True,alpha = 0.5)

Mean = np.mean(Output[:10000,Node,-1])
StdDev = np.std(Output[:10000,Node,-1])
def normal_dist(mean,variance):
	stddev = np.sqrt(variance)
	x = np.linspace(mean-3*stddev,mean+3*stddev,100)
	y = 1./(np.sqrt(2 * np.pi * variance)) * np.exp(- (x-mean)**2 / (2*variance))
	return x,y


x,y = normal_dist(Mean,StdDev**2)
#x = np.linspace(A[1][0],A[1][-1],100)
#y = coefs_kernal.pdf(x)
axs.plot(x,y)
axs.set_xlabel('Head (m)')
axs.set_ylabel('Probability')
axs.set_title('Node:' + str(Node+2))
#pp.savefig(Directory+'Monte_PCE_NoSamples'+str(NoSamples)+'_Node'+str(Node+2)+'_dist')
pp.show()

